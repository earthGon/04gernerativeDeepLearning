{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실습 data preprocess는 모두 gan GDL github 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions 100\n"
     ]
    }
   ],
   "source": [
    "from utils.write import training_data, test_data, collapse_documents, expand_answers, _read_data, glove\n",
    "training_data_gen = training_data()\n",
    "# training_data_gen = [next(training_data_gen)]\n",
    "test_data_gen = test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = next(training_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_tokens\n",
      " [3695    5  856    1 4601    1   66    4  219   99  216   10  856 3345\n",
      "   15 1119  339   29   33 3854  221    8 2630 6558    5   28   22  194\n",
      "  676 2743   10    4  123   12  139    6   29   54  410   33  909   11\n",
      "  529    7  194  821   10 6558    5   35   23   12  162 5156   66  124\n",
      "   91    1 6167    1 4571   66    8  159   30  151 1399  963   64    5\n",
      "   28 2683 3549 9316  154   11 1076  172  447  183   20  796    1    5\n",
      "    4  940  597 2077 2017    8    4  123    6    4  172  447    1   20\n",
      "   11  527   24   99  496    7  474  889 3289    5   39   18   53    8\n",
      "  699   20 4571    6 9316 2601   11  178  952   95 1086   10    4 5393\n",
      " 6558  623   22  199   22   38  738    5   35  150    1    9 9316 6711\n",
      "   15  181  209    1 2854  706   13 9952 1119  399  106   30 1999   87\n",
      " 1086    6  120   22   10    4  396    1  952    5    4  714    5   40\n",
      "   19    5   17    8 1860    4  279    7    4 1723   70    6   29  102\n",
      "   42  268   54  461 2240   60  821   10  856  433   17   84   82  837\n",
      "    8 1941   98    4]\n",
      "\n",
      "\n",
      "question_input_tokens\n",
      " [   2   62   87   23 1086  188    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "\n",
      "\n",
      "answer_masks\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "\n",
      "answer_labels\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "question_output_tokens\n",
      " [  62   87   23 1086  188    3    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "print('document_tokens\\n', t['document_tokens'][idx])\n",
    "print('\\n')\n",
    "print('question_input_tokens\\n', t['question_input_tokens'][idx])\n",
    "print('\\n')\n",
    "print('answer_masks\\n', t['answer_masks'][idx])\n",
    "print('\\n')\n",
    "print('answer_labels\\n', t['answer_labels'][idx])\n",
    "print('\\n')\n",
    "print('question_output_tokens\\n', t['question_output_tokens'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE\n",
      "VOCAB_SIZE:  9984\n",
      "EMBEDDING_DIMENS:  100\n"
     ]
    }
   ],
   "source": [
    "# GloVe\n",
    "\n",
    "VOCAB_SIZE = glove.shape[0]\n",
    "EMBEDDING_DIMENS = glove.shape[1]\n",
    "\n",
    "print('GLOVE')\n",
    "print('VOCAB_SIZE: ', VOCAB_SIZE)\n",
    "print('EMBEDDING_DIMENS: ', EMBEDDING_DIMENS)\n",
    "\n",
    "GRU_UNITS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DOC_SIZE = None\n",
    "MAX_ANSWER_SIZE = None\n",
    "MAX_Q_SIZE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import RMSprop,Adam\n",
    "\n",
    "class answerMask(nn.Module):\n",
    "    def __init__(self,seq_length=200):\n",
    "        super().__init__()\n",
    "        self.seq_length = 200    \n",
    "        self.n_units = 128\n",
    "        embedding_size = self.n_units #n_units에 맞추기\n",
    "        total_words = 9984 # gloVe dim에 맞추기\n",
    "        self.num_layers = 1 #적층 레이어를 위해\n",
    "        self.batch_size =1\n",
    "\n",
    "        self.embed = nn.Embedding(\n",
    "            num_embeddings=total_words, embedding_dim= embedding_size\n",
    "        )\n",
    "        self.answer_mask_gru = nn.GRU(\n",
    "            input_size=self.n_units,\n",
    "            hidden_size=self.n_units,\n",
    "            batch_first=True,\n",
    "            dropout=0.2,            \n",
    "        )\n",
    "        self.answer_mask = nn.Sequential(\n",
    "            nn.Linear(self.n_units,2), \n",
    "            nn.Softmax(), \n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = Adam(self.parameters(),lr=0.001)\n",
    "    def forward(self,x,prev_state):  \n",
    "        # [126, 200]\n",
    "        print(\"x.shape\",x.shape)\n",
    "        emb_init = self.embed(x) \n",
    "        # [126, 200, 128] #prev_state [1, 126, 128]을 원함\n",
    "        print(\"emb_init.shape\",emb_init.shape)\n",
    "        self.output,state =self.answer_mask_gru(emb_init,prev_state)\n",
    "        # [126, 200, 128] [1, 126, 128]\n",
    "        print(\"self.output.shape\",self.output.shape)\n",
    "        print(\"state.shape\",state.shape)\n",
    "        mask = self.answer_mask(self.output)\n",
    "        # [126, 200, 2]\n",
    "        print(\"mask.shape\",mask.shape)\n",
    "        return mask \n",
    "\n",
    "    def init_state(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.n_units)\n",
    "    \n",
    "    def build_loss(self,document,answer_label):\n",
    "        self.batch_size = document.shape[0]\n",
    "        state_h = self.init_state()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        y_pred = self.forward(document, state_h)\n",
    "        y_pred = y_pred.view(-1,2)\n",
    "        loss = self.loss_fn(y_pred, answer_label)\n",
    "\n",
    "        # loss.backward()\n",
    "        # self.optimizer.step()\n",
    "\n",
    "        return loss\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QnAEncoderDecoderModel(nn.Module):\n",
    "    def __init__(self,seq_length=20):\n",
    "        super().__init__()\n",
    "        \n",
    "        # n_units = 256\n",
    "        # embedding_size = 100\n",
    "        self.seq_length =200\n",
    "        self.n_units = 128\n",
    "        self.num_layers = 1 #적층 레이어를 위해\n",
    "        self.total_words = 9984 # gloVe dim에 맞추기\n",
    "        \n",
    "        self.encoder_gru = nn.GRU(\n",
    "            input_size=self.n_units,\n",
    "            hidden_size=self.n_units,\n",
    "            batch_first=True,\n",
    "            dropout=0.2,            \n",
    "        )\n",
    "\n",
    "        self.decoder_gru = nn.GRU(\n",
    "            input_size=self.n_units,\n",
    "            hidden_size=self.n_units,\n",
    "            batch_first=True,\n",
    "            dropout=0.2,            \n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_units,self.total_words),\n",
    "            nn.Softmax(),\n",
    "        )      \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = Adam(self.parameters(),lr=0.001)\n",
    "        self.dec_state =None #나중에 질문 생성을 위해\n",
    "\n",
    "    def forward(self,encoder_inputs,question,prev_state):  \n",
    "        # encoder_inputs [126, 25, 128]  #h_0 [1, 126, 128]을 원함. [1, 25, 128]\n",
    "        print(\"encoder_inputs.shape\",encoder_inputs.shape)\n",
    "        print(\"question.shape\",question.shape)\n",
    "        enc_output,enc_state = self.encoder_gru(encoder_inputs,prev_state)\n",
    "        # [126, 25, 128], [1, 126, 128]\n",
    "        print(\"enc_output.shape\",enc_output.shape)\n",
    "        print(\"enc_state.shape\",enc_state.shape)\n",
    "        # question [126, 13]\n",
    "        emb_question = self.embed(question).detach()\n",
    "        # [126, 13, 128]\n",
    "        print(\"emb_question.shape\",emb_question.shape)\n",
    "        dec_output,self.dec_state = self.decoder_gru( emb_question ,enc_state)\n",
    "        # [126, 13, 128], [1, 126, 128]\n",
    "        print(\"dec_output.shape\",dec_output.shape)\n",
    "        print(\"dec_state.shape\",self.dec_state.shape)\n",
    "\n",
    "        logits = self.fc(dec_output) \n",
    "        print(\"logits.shape\",logits.shape)\n",
    "        #[126, 13, 9984]\n",
    "        return logits\n",
    "    \n",
    "    def init_state(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.n_units)\n",
    "\n",
    "    def answerMaskDotAnswerOutputs(self,answer_mask_label,answer_outputs):\n",
    "        # [119, 51, 200] x [119, 200, 512]\n",
    "        encoder_inputs = torch.bmm(answer_mask_label,answer_outputs)\n",
    "        # [119, 51, 512]\n",
    "        return encoder_inputs\n",
    "\n",
    "    def predictY(self,answer_mask_model,question_input_token,answer_mask_label):\n",
    "        self.embed = answer_mask_model.embed\n",
    "        \n",
    "        encoder_inputs = self.answerMaskDotAnswerOutputs(answer_mask_label,answer_mask_model.output)\n",
    "        \n",
    "        self.batch_size=encoder_inputs.shape[0]\n",
    "        state_h = self.init_state()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = self.forward(encoder_inputs,question_input_token, state_h)\n",
    "        return y_pred\n",
    "\n",
    "    def build_loss(self,answer_mask_model,question_input_token,question_output_token,answer_mask_label):\n",
    "        y_pred = self.predictY(answer_mask_model,question_input_token,answer_mask_label)\n",
    "        y_pred = y_pred.view(-1,self.total_words)\n",
    "        loss = self.loss_fn(y_pred, question_output_token)\n",
    "\n",
    "        # loss.backward()\n",
    "        # self.optimizer.step()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "answer_mask_model = answerMask()\n",
    "qna_model = QnAEncoderDecoderModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1\n",
      "hi\n",
      "x.shape torch.Size([126, 200])\n",
      "emb_init.shape torch.Size([126, 200, 128])\n",
      "self.output.shape torch.Size([126, 200, 128])\n",
      "state.shape torch.Size([1, 126, 128])\n",
      "mask.shape torch.Size([126, 200, 2])\n",
      "===hi===\n",
      "encoder_inputs.shape torch.Size([126, 42, 128])\n",
      "question.shape torch.Size([126, 17])\n",
      "enc_output.shape torch.Size([126, 42, 128])\n",
      "enc_state.shape torch.Size([1, 126, 128])\n",
      "emb_question.shape torch.Size([126, 17, 128])\n",
      "dec_output.shape torch.Size([126, 17, 128])\n",
      "dec_state.shape torch.Size([1, 126, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.shape torch.Size([126, 17, 9984])\n",
      "0: 훈련 손실: 9.9012\n",
      "hi\n",
      "x.shape torch.Size([128, 200])\n",
      "emb_init.shape torch.Size([128, 200, 128])\n",
      "self.output.shape torch.Size([128, 200, 128])\n",
      "state.shape torch.Size([1, 128, 128])\n",
      "mask.shape torch.Size([128, 200, 2])\n",
      "===hi===\n",
      "encoder_inputs.shape torch.Size([128, 25, 128])\n",
      "question.shape torch.Size([128, 15])\n",
      "enc_output.shape torch.Size([128, 25, 128])\n",
      "enc_state.shape torch.Size([1, 128, 128])\n",
      "emb_question.shape torch.Size([128, 15, 128])\n",
      "dec_output.shape torch.Size([128, 15, 128])\n",
      "dec_state.shape torch.Size([1, 128, 128])\n",
      "logits.shape torch.Size([128, 15, 9984])\n",
      "1: 훈련 손실: 9.9008\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_loss_hist = []\n",
    "test_loss_hist = []\n",
    "\n",
    "#EPOCHS = 2000\n",
    "EPOCHS = 1\n",
    "start_epoch = 1\n",
    "for epoch in range(start_epoch, start_epoch + EPOCHS + 1):\n",
    "    print(\"에포크 {0}\".format(epoch))\n",
    "    \n",
    "    for i, batch in enumerate(training_data()):\n",
    "        \n",
    "        val_batch = next(test_data_gen, None)\n",
    "        \n",
    "        if val_batch is None:\n",
    "            test_data_gen = test_data()\n",
    "            val_batch = next(test_data_gen, None)\n",
    "        print('hi')\n",
    "        answer_training_loss = answer_mask_model.build_loss(\n",
    "            torch.LongTensor( batch['document_tokens']),\n",
    "            torch.LongTensor(batch['answer_labels'].flatten()),\n",
    "        )\n",
    "        print('===hi===')\n",
    "        decoder_training_loss = qna_model.build_loss(\n",
    "            answer_mask_model,\n",
    "            torch.LongTensor(batch['question_input_tokens']),\n",
    "            torch.LongTensor(batch['question_output_tokens'].flatten()),\n",
    "            torch.FloatTensor( batch['answer_masks']),\n",
    "        )\n",
    "        \n",
    "    \n",
    "        \n",
    "        total_loss = answer_training_loss+ decoder_training_loss\n",
    "        training_loss_hist.append(total_loss.item())\n",
    "        total_loss.backward()\n",
    "        answer_mask_model.optimizer.step()\n",
    "        qna_model.optimizer.step()\n",
    "\n",
    "\n",
    "        print(f\"{i}: 훈련 손실: {total_loss.item():.4f}\")    \n",
    "        if i==1:\n",
    "            break\n",
    "#    if epoch % 100 == 0:\n",
    "#        print(f\"{i}: 훈련 손실: {total_loss:.4f}\")    \n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트  \n",
    "gan gdl 참고 후 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['july', '31st', '2005', '.', '']\n",
      "0 the\n",
      "1 winning\n",
      "2 goal\n",
      "3 was\n",
      "4 scored\n",
      "5 by\n",
      "6 23-year-old\n",
      "7 striker\n",
      "8 joe\n",
      "9 bloggs\n",
      "10 during\n",
      "11 the\n",
      "12 match\n",
      "13 between\n",
      "14 arsenal\n",
      "15 and\n",
      "16 barcelona\n",
      "17 .\n",
      "18 arsenal\n",
      "19 recently\n",
      "20 signed\n",
      "21 the\n",
      "22 striker\n",
      "23 for\n",
      "24 50\n",
      "25 million\n",
      "26 pounds\n",
      "27 .\n",
      "28 the\n",
      "29 next\n",
      "30 match\n",
      "31 is\n",
      "32 in\n",
      "33 two\n",
      "34 weeks\n",
      "35 time,\n",
      "36 on\n",
      "37 july\n",
      "38 31st\n",
      "39 2005\n",
      "40 .\n",
      "41 \n"
     ]
    }
   ],
   "source": [
    "test_data_gen = test_data()\n",
    "batch = next(test_data_gen)\n",
    "batch = collapse_documents(batch)\n",
    "idx=0\n",
    "print(batch['document_words'][idx][37:50])\n",
    "for i in range(len(batch['document_words'][idx])):\n",
    "    print(i, batch['document_words'][idx][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape torch.Size([1, 42])\n",
      "emb_init.shape torch.Size([1, 42, 128])\n",
      "self.output.shape torch.Size([1, 42, 128])\n",
      "state.shape torch.Size([1, 1, 128])\n",
      "mask.shape torch.Size([1, 42, 2])\n",
      "예측한 대답의 확률\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 the 1.0\n",
      "1 winning 1.0\n",
      "2 goal 1.0\n",
      "3 was 1.0\n",
      "4 scored 1.0\n",
      "5 by 1.0\n",
      "6 23-year-old 1.0\n",
      "7 striker 1.0\n",
      "8 joe 1.0\n",
      "9 bloggs 1.0\n",
      "10 during 1.0\n",
      "11 the 1.0\n",
      "12 match 1.0\n",
      "13 between 1.0\n",
      "14 arsenal 1.0\n",
      "15 and 1.0\n",
      "16 barcelona 1.0\n",
      "17 . 1.0\n",
      "18 arsenal 1.0\n",
      "19 recently 1.0\n",
      "20 signed 1.0\n",
      "21 the 1.0\n",
      "22 striker 1.0\n",
      "23 for 1.0\n",
      "24 50 1.0\n",
      "25 million 1.0\n",
      "26 pounds 1.0\n",
      "27 . 1.0\n",
      "28 the 1.0\n",
      "29 next 1.0\n",
      "30 match 1.0\n",
      "31 is 1.0\n",
      "32 in 1.0\n",
      "33 two 1.0\n",
      "34 weeks 1.0\n",
      "35 time, 1.0\n",
      "36 on 1.0\n",
      "37 july 1.0\n",
      "38 31st 1.0\n",
      "39 2005 1.0\n",
      "40 . 1.0\n",
      "41  1.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 대답 위치 예측\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "idx = 0\n",
    "\n",
    "answer_mask_model.batch_size = torch.LongTensor( batch['document_tokens']).shape[0]\n",
    "answer_preds = answer_mask_model(torch.LongTensor( batch['document_tokens']),answer_mask_model.init_state())\n",
    "\n",
    "print('예측한 대답의 확률')\n",
    "ax = plt.gca()\n",
    "ax.xaxis.grid(True)\n",
    "plt.plot(answer_preds[idx, :, 1].detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(batch['document_words'][idx])):\n",
    "    print(i, batch['document_words'][idx][i], np.round(answer_preds[idx][i][1].detach().numpy(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['july', '31st', '2005']\n"
     ]
    }
   ],
   "source": [
    "# 대답 위치 선정\n",
    "\n",
    "start_answer = 37\n",
    "end_answer = 39\n",
    "\n",
    "print(batch['document_words'][idx][start_answer:(1+end_answer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape torch.Size([1, 42])\n",
      "emb_init.shape torch.Size([1, 42, 128])\n",
      "self.output.shape torch.Size([1, 42, 128])\n",
      "state.shape torch.Size([1, 1, 128])\n",
      "mask.shape torch.Size([1, 42, 2])\n",
      "[[   4  873  714   18  874   24 9870 3183 1959    1  105    4  549  118\n",
      "  3562    9 3567    6 3562  742  756    4 3183   13  691   94 1678    6\n",
      "     4  182  549   17   10   56  516    1   16  374    1  708    6    1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "answer_mask_model.batch_size = torch.LongTensor( batch['document_tokens']).shape[0]\n",
    "answer_preds = answer_mask_model(torch.LongTensor( batch['document_tokens']),answer_mask_model.init_state())\n",
    "\n",
    "answers = [[0] * len(answer_preds[idx])]\n",
    "for i in range(start_answer, end_answer + 1):\n",
    "    answers[0][i] = 1\n",
    "\n",
    "answer_batch = expand_answers(batch, answers)\n",
    "print(answer_batch['document_tokens'][[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape torch.Size([1, 42])\n",
      "emb_init.shape torch.Size([1, 42, 128])\n",
      "self.output.shape torch.Size([1, 42, 128])\n",
      "state.shape torch.Size([1, 1, 128])\n",
      "mask.shape torch.Size([1, 42, 2])\n",
      "encoder_inputs.shape torch.Size([1, 3, 128])\n",
      "question.shape torch.Size([1, 42])\n",
      "enc_output.shape torch.Size([1, 3, 128])\n",
      "enc_state.shape torch.Size([1, 1, 128])\n",
      "emb_question.shape torch.Size([1, 42, 128])\n",
      "dec_output.shape torch.Size([1, 42, 128])\n",
      "dec_state.shape torch.Size([1, 1, 128])\n",
      "logits.shape torch.Size([1, 42, 9984])\n",
      "next_decoder_init_state.shape torch.Size([1, 1, 128])\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n",
      "look_up_token(word_tokens[0].detach().numpy()) <PAD>\n"
     ]
    }
   ],
   "source": [
    "from utils.write import START_TOKEN, END_TOKEN, look_up_token\n",
    "\n",
    "answer_mask_model.batch_size = torch.LongTensor( batch['document_tokens']).shape[0]\n",
    "answer_preds = answer_mask_model(torch.LongTensor( batch['document_tokens']),answer_mask_model.init_state())\n",
    "\n",
    "answers = [[0] * len(answer_preds[idx])]\n",
    "for i in range(start_answer, end_answer + 1):\n",
    "    answers[0][i] = 1\n",
    "\n",
    "answer_batch = expand_answers(batch, answers)\n",
    "with torch.no_grad():\n",
    "    qna_model.predictY(\n",
    "        answer_mask_model,\n",
    "        torch.LongTensor( answer_batch['document_tokens'][[idx]]), \n",
    "        torch.FloatTensor(answer_batch['answer_masks'][[idx]]))\n",
    "    next_decoder_init_state = qna_model.dec_state\n",
    "    print(\"next_decoder_init_state.shape\",next_decoder_init_state.shape)\n",
    "\n",
    "    word_tokens = [START_TOKEN]\n",
    "    questions = [look_up_token(START_TOKEN)]\n",
    "\n",
    "    ended = False\n",
    "    counter = 0\n",
    "\n",
    "    while not ended:\n",
    "        \n",
    "        counter += 1\n",
    "        #print(\"torch.LongTensor(word_tokens)\",torch.LongTensor(word_tokens).unsqueeze(1).shape)\n",
    "        emb_output=qna_model.embed(torch.LongTensor(word_tokens).unsqueeze(1))\n",
    "        #print(\"emb_output\",emb_output.shape)\n",
    "        decoder_output, next_decoder_init_state = qna_model.decoder_gru( \n",
    "            emb_output,\n",
    "            next_decoder_init_state)\n",
    "        \n",
    "        word_preds = qna_model.fc(decoder_output)\n",
    "        #print(\"word_preds.shape\",word_preds.shape)\n",
    "        word_tokens = torch.argmax(word_preds, 2)[0]\n",
    "        print(\"look_up_token(word_tokens[0].detach().numpy())\",look_up_token(word_tokens[0].detach().numpy()))\n",
    "        questions.append(look_up_token(word_tokens[0].detach().numpy()))\n",
    "\n",
    "        if word_tokens[0] == END_TOKEN or counter > 20 :\n",
    "            ended = True\n",
    "\n",
    "    questions = ' '.join(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_gen = test_data()\n",
    "batch = next(test_data_gen)\n",
    "batch = collapse_documents(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 200)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['document_tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(128, 200, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(batch['answer_labels'].shape)\n",
    "np.expand_dims(batch['answer_labels'], axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(121, 18, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(batch['question_output_tokens'].shape)\n",
    "np.expand_dims(batch['question_output_tokens'], axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 대답 위치 예측\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "idx = 0\n",
    "\n",
    "answer_preds = answer_model.predict(batch[\"document_tokens\"])\n",
    "\n",
    "print('예측한 대답의 확률')\n",
    "ax = plt.gca()\n",
    "ax.xaxis.grid(True)\n",
    "plt.plot(answer_preds[idx, :, 1])\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(batch['document_words'][idx])):\n",
    "    print(i, batch['document_words'][idx][i], np.round(answer_preds[idx][i][1],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['july', '31st', '2005']\n",
      "['the', 'winning', 'goal', 'was', 'scored', 'by', '23-year-old', 'striker', 'joe', 'bloggs', 'during', 'the', 'match', 'between', 'arsenal', 'and', 'barcelona', '.', 'arsenal', 'recently', 'signed', 'the', 'striker', 'for', '50', 'million', 'pounds', '.', 'the', 'next', 'match', 'is', 'in', 'two', 'weeks', 'time,', 'on', 'july', '31st', '2005', '.', '']\n"
     ]
    }
   ],
   "source": [
    "# 대답 위치 선정\n",
    "\n",
    "start_answer = 37\n",
    "end_answer = 39\n",
    "print(batch['document_words'][idx][start_answer:(1+end_answer)])\n",
    "print(batch['document_words'][idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   4,  873,  714,   18,  874,   24, 9870, 3183, 1959,    1,  105,\n",
       "           4,  549,  118, 3562,    9, 3567,    6, 3562,  742,  756,    4,\n",
       "        3183,   13,  691,   94, 1678,    6,    4,  182,  549,   17,   10,\n",
       "          56,  516,    1,   16,  374,    1,  708,    6,    1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = [[0] * 40]\n",
    "for i in range(start_answer, end_answer + 1):\n",
    "    answers[0][i] = 1\n",
    "    print(answers)\n",
    "\n",
    "answer_batch = expand_answers(batch, answers)\n",
    "answer_batch['document_tokens'][[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_batch['answer_masks'][[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_preds = answer_model.predict(batch[\"document_tokens\"])\n",
    "\n",
    "answers = [[0] * len(answer_preds[idx])]\n",
    "for i in range(start_answer, end_answer + 1):\n",
    "    answers[0][i] = 1\n",
    "\n",
    "answer_batch = expand_answers(batch, answers)\n",
    "\n",
    "next_decoder_init_state = decoder_initial_state_model.predict([answer_batch['document_tokens'][[idx]], answer_batch['answer_masks'][[idx]]])\n",
    "\n",
    "word_tokens = [START_TOKEN]\n",
    "questions = [look_up_token(START_TOKEN)]\n",
    "\n",
    "ended = False\n",
    "counter = 0\n",
    "\n",
    "while not ended:\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "    word_preds, next_decoder_init_state = question_model.predict([word_tokens, next_decoder_init_state])\n",
    "\n",
    "    next_decoder_init_state = np.squeeze(next_decoder_init_state, axis = 1)\n",
    "    word_tokens = np.argmax(word_preds, 2)[0]\n",
    "\n",
    "    questions.append(look_up_token(word_tokens[0]))\n",
    "\n",
    "    if word_tokens[0] == END_TOKEN or counter > 20 :\n",
    "        ended = True\n",
    "\n",
    "questions = ' '.join(questions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "747fe91b7bc9ec9d8624ac8c139c41948fb906c2c40d5ffbc4d71da454373257"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
